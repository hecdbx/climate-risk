# Databricks Cluster Configuration for Climate Risk Modeling

cluster_config:
  cluster_name: "climate-risk-analysis"
  spark_version: "14.3.x-scala2.12"
  node_type_id: "i3.xlarge"
  driver_node_type_id: "i3.xlarge"
  num_workers: 4
  autotermination_minutes: 120
  
  # Geospatial libraries and dependencies
  libraries:
    - pypi:
        package: "geopandas==0.14.1"
    - pypi:
        package: "folium==0.15.1"
    - pypi:
        package: "plotly==5.17.0"
    - pypi:
        package: "rasterio==1.3.9"
    - pypi:
        package: "xarray==2023.12.0"
    - pypi:
        package: "netCDF4==1.6.5"
    - pypi:
        package: "h3==3.7.6"
    - pypi:
        package: "scikit-learn==1.3.2"
    - pypi:
        package: "pandas==2.1.4"
    - pypi:
        package: "numpy==1.24.4"
    
  # Spark configuration for geospatial processing
  spark_conf:
    "spark.sql.adaptive.enabled": "true"
    "spark.sql.adaptive.coalescePartitions.enabled": "true"
    "spark.serializer": "org.apache.spark.serializer.KryoSerializer"
    "spark.kryo.registrator": "org.apache.spark.sql.catalyst.expressions.UnsafeRowSerializer"
    "spark.databricks.delta.optimizeWrite.enabled": "true"
    "spark.databricks.delta.autoCompact.enabled": "true"

# Environment variables
environment:
  CLIMATE_DATA_PATH: "/mnt/climate-data/"
  ELEVATION_DATA_PATH: "/mnt/elevation-data/"
  OUTPUT_PATH: "/mnt/risk-models/"
  
# Data sources configuration
data_sources:
  precipitation:
    source: "NOAA_PRISM"
    resolution: "4km"
    update_frequency: "monthly"
  
  temperature:
    source: "ERA5_REANALYSIS"
    resolution: "25km"
    update_frequency: "daily"
    
  elevation:
    source: "USGS_NED"
    resolution: "30m"
    format: "GeoTIFF"
    
  historical_events:
    drought_events: "/data/drought_events.parquet"
    flood_events: "/data/flood_events.parquet"
